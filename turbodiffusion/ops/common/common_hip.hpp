// !!! This is a file automatically generated by hipify!!!
#pragma once

#include <hip/hip_runtime.h>
#include <torch/torch.h>
#include <torch/extension.h>

// Define CUTLASS macros for HIP compatibility
#ifndef CUTLASS_HOST_DEVICE
#define CUTLASS_HOST_DEVICE __host__ __device__
#endif
#ifndef CUTLASS_DEVICE
#define CUTLASS_DEVICE __device__
#endif
#ifndef CUTLASS_HOST
#define CUTLASS_HOST __host__
#endif

// Define __grid_constant__ if not available (CUDA 11.5+ feature)
#ifndef __grid_constant__
#define __grid_constant__
#endif

// Define CUTLASS pragma macros for HIP
#ifndef CUTLASS_PRAGMA_UNROLL
#define CUTLASS_PRAGMA_UNROLL _Pragma("unroll")
#endif
#ifndef CUTLASS_PRAGMA_NO_UNROLL
#define CUTLASS_PRAGMA_NO_UNROLL _Pragma("nounroll")
#endif

inline CUTLASS_HOST_DEVICE int64_t cdiv(int64_t const& a, int64_t const &b) {
  return (a + b - 1) / b;
}

// Note: Don't define max/min as they conflict with HIP builtins
// Use std::max/std::min or the built-in max/min instead

#define MIN(a, b) ((a) > (b) ? (b) : (a))
#define MAX(a, b) ((a) > (b) ? (a) : (b))

#define BOOL_SWITCH(COND, CONST_NAME, ...)    \
[&] {                                         \
  if (COND) {                                 \
    static constexpr bool CONST_NAME = true;  \
    return (__VA_ARGS__)();                   \
  } else {                                    \
    static constexpr bool CONST_NAME = false; \
    return (__VA_ARGS__)();                   \
  }                                           \
}() 

#define CUDA_CHECK(call)    \
{                           \
  hipError_t err = call;   \
  if (err != hipSuccess) { \
    fprintf(stderr, "CUDA Error at %s:%d: %s\n", __FILE__, __LINE__, hipGetErrorString(err)); \
    exit(err);              \
  }                         \
}

#define CONFIG_SWITCH(N, ...)                                   \
[&] {                                                           \
  if (N <= 1024) {                                              \
    constexpr int NUM_THR_PER_CTA = 128;                        \
    constexpr int MAX_HIDDEN_SIZE = 1024;                       \
    return (__VA_ARGS__)();                                     \
  } else if (N <= 2048) {                                       \
    constexpr int NUM_THR_PER_CTA = 128;                        \
    constexpr int MAX_HIDDEN_SIZE = 2048;                       \
    return (__VA_ARGS__)();                                     \
  } else if (N <= 4096) {                                       \
    constexpr int NUM_THR_PER_CTA = 128;                        \
    constexpr int MAX_HIDDEN_SIZE = 4096;                       \
    return (__VA_ARGS__)();                                     \
  } else if (N <= 8192) {                                       \
    constexpr int NUM_THR_PER_CTA = 256;                        \
    constexpr int MAX_HIDDEN_SIZE = 8192;                       \
    return (__VA_ARGS__)();                                     \
  } else {                                                      \
    constexpr int NUM_THR_PER_CTA = 256;                        \
    constexpr int MAX_HIDDEN_SIZE = 16384;                      \
    return (__VA_ARGS__)();                                     \
  }                                                             \
}()


template <int BlockSize>
  void create_tensor(
    torch::Device const &device,
    std::optional<at::Tensor> &output,
    std::optional<at::Tensor> &scale,
    int m, int n
  ) {
    int num_block_m = cdiv(m, BlockSize);
    int num_block_n = cdiv(n, BlockSize);
    if (!output.has_value()) {
      output.emplace(torch::empty(
        {m, n},
        torch::TensorOptions().device(device).dtype(torch::kInt8)
      ));
      scale.emplace(torch::empty(
        {num_block_m, num_block_n},
        torch::TensorOptions().device(device).dtype(torch::kFloat32)
      ));
    }
  }

